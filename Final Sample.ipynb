{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At first I have manually sorted the files to two different locations and then added them together to create the dataset along with their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, preprocessing,naive_bayes,metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "Tokensier = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file):\n",
    "    file = re.sub(r'[^a-zA-Z\\s]', '', file, re.I|re.A)    # lower case and remove special characters\\whitespaces\n",
    "    file = file.lower()\n",
    "    file = file.strip()\n",
    "    tokens = Tokensier.tokenize(file)                                                     \n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    file = ' '.join(filtered_tokens)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(typ,norm):\n",
    "    if typ==1:\n",
    "        rootdir=\"/Amen/\" # to check define your path for amendment files\n",
    "        for i in range(1,312):\n",
    "            with open(rootdir+f'AA{i}.txt', 'r') as myfile:\n",
    "                data = myfile.read().replace('\\n', '')\n",
    "            data = np.array(data)\n",
    "            text_mec = np.vectorize(preprocess)\n",
    "            if i==1:\n",
    "                norm_corpus = text_mec(data)\n",
    "            else:\n",
    "                norm_corpus=np.vstack((norm_corpus,text_mec(data)))\n",
    "        return norm_corpus\n",
    "    else:\n",
    "        root=\"/Agg_Emp\" ## to check define your path for without amendment files\n",
    "        for subdir, dirs, files in os.walk(root):\n",
    "            for file in files:\n",
    "                if file.endswith('.txt'):\n",
    "                    with open(root+'/'+file, 'r') as myfile:\n",
    "                        data=myfile.read().replace('\\n', '')\n",
    "                    data = np.array(data)\n",
    "                    text_mec= np.vectorize(preprocess)\n",
    "                    norm=np.vstack((norm,text_mec(data)))\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Dataframe(norm_corpus):\n",
    "    df=pd.DataFrame(data=norm_corpus,columns=[\"text\"])\n",
    "    df['label']=1\n",
    "    for i,row in df.iterrows():    \n",
    "        if i>311:\n",
    "            df.iloc[i,df.columns.get_loc('label')]=0\n",
    "    result = df.sample(frac=1).reset_index(drop=True)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, train_x, train_y, test_x,test_y):\n",
    "    classifier.fit(train_x, train_y)\n",
    "    predictions = classifier.predict(test_x)\n",
    "    return metrics.accuracy_score(predictions, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus=create_dataset(1,[])\n",
    "norm_corpus=create_dataset(0,norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=Make_Dataframe(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x, train_y, test_y = model_selection.train_test_split(result['text'], result['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(result['text'])\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf= TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf.fit(result['text'])\n",
    "train_x_tf =tfidf.transform(train_x)\n",
    "test_x_tf= tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier with TF 0.8924731182795699\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(),train_x_tf, train_y,test_x_tf,test_y)\n",
    "print(\"Accuracy of Naive Bayes Classifier with TF\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes Classifier with Count Vectors 0.8817204301075269\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(fit_prior=False), xtrain_count, train_y, xvalid_count,test_y)\n",
    "print(\"Accuracy of Naive Bayes Classifier with Count Vectors\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to check the prediction for a file\n",
    "# Output: 1- Amendment letter 0- employement letter\n",
    "predictions = classifier.predict(test_x_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
